# langchain-chromadb-rag-example
My attempt at implementing RAG on Ollama and other LLM services using chromadb and langchain

## Todo:
- [X] Initial example of RAG working with Ollama and Langchain
- [X] Continuously listen for input
- [X] Continuously monitor changes in the RAG ingestion folder
- [X] Persistant memory using Chromadb
- [X] Divide everything into related files (rag_handler, chat, chroma etc.)
- [ ] Support for ChromaDB running on another address (if that's possible?)
- [X] Refactor
- [X] Dockerize
- [ ] Update readme to cover installation and troubleshooting etc.
- [ ] Adding other LLM services (maybe?)
