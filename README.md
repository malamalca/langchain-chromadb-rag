# langchain-chromadb-rag-example
My attempt at implementing RAG on Ollama and other LLM services using chromadb and langchain

## Todo:
- [X] Initial example of RAG working with Ollama and Langchain
- [X] Continuously listen for input
- [X] Continuously monitor changes in the RAG ingestion folder
- [ ] Persistant memory using Chromadb
- [ ] Support for ChromaDB running on another address (if that's possible?)
- [ ] Refactor
- [ ] Dockerize
- [ ] Update readme to cover installation and troubleshooting etc.
- [ ] Adding other LLM services (maybe?)
