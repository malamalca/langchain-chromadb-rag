# langchain-chromadb-rag-example
My attempt at implementing RAG on Ollama and other LLM services using chromadb and langchain

## Todo:
- [X] Initial example of RAG working with Ollama and Langchain
- [X] Continuously listen for input
- [X] Continuously monitor changes in the RAG ingestion folder
- [ ] Persistant memory using Chromadb
- [ ] Refactor
- [ ] Dockerizing
- [ ] Adding other LLM services (maybe?)
