# langchain-chromadb-rag-example
My attempt at implementing RAG on Ollama and other LLM services using chromadb and langchain

## Todo:
- [ ] Initial example of RAG working with Ollama and Langchain
- [ ] Persistant memory using Chromadb
- [ ] Continuously listen for input
- [ ] Continuously monitor changes in the RAG ingestion folder
- [ ] Dockerizing
- [ ] Adding other LLM services (maybe?)
